{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Downstream.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "DwYqv2YNjbOp",
        "colab_type": "code",
        "outputId": "0bb1f0a0-2a04-4739-e928-08cf7d26575c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131304 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sxhkaRiijrwg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive  -o nonempty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P83ux4eWjxE_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('drive/bertlab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8mDy12l3j9Mg",
        "colab_type": "code",
        "outputId": "0529d70c-5aca-441f-ad0e-d7a845ad2908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention.py\t\t    modeling_test.py\n",
            "bert\t\t\t    multilingual.md\n",
            "bertbert.py\t\t    optimization.py\n",
            "bertcode\t\t    optimization_test.py\n",
            "berteval\t\t    position.py\n",
            "Bert-lab\t\t    predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n",
            "BERTmodel\t\t    __pycache__\n",
            "CONTRIBUTING.md\t\t    README.md\n",
            "crazy.py\t\t    requirements.txt\n",
            "create_pretraining_data.py  run_classifier.py\n",
            "download_glue_data.py\t    run_classifier_with_tfhub.py\n",
            "extract_features.py\t    run_pretraining.py\n",
            "feature\t\t\t    run_squad.py\n",
            "forbert\t\t\t    sample_text.txt\n",
            "__init__.py\t\t    self_attention.py\n",
            "labresult\t\t    tokenization.py\n",
            "LICENSE\t\t\t    tokenization_test.py\n",
            "modeling.py\t\t    version2.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l78xdtP3j_aP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#loading self_attention module\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.engine import Layer\n",
        "from keras.utils import get_custom_objects\n",
        "\n",
        "\n",
        "class _BaseMultiHeadAttention(Layer):\n",
        "  \n",
        "    def __init__(self, num_heads: int, use_masking: bool,\n",
        "                 dropout: float = 0.0,\n",
        "                 compression_window_size: int = None,\n",
        "                 **kwargs):\n",
        "     \n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.use_masking = use_masking\n",
        "        self.dropout = dropout\n",
        "        if (compression_window_size is not None\n",
        "                and compression_window_size <= 0):\n",
        "            assert ValueError(\n",
        "                f\"Too small compression window ({compression_window_size})\")\n",
        "        self.compression_window_size = compression_window_size\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config['num_heads'] = self.num_heads\n",
        "        config['use_masking'] = self.use_masking\n",
        "        config['dropout'] = self.dropout\n",
        "        config['compression_window_size'] = self.compression_window_size\n",
        "        return config\n",
        "\n",
        "    def build_output_params(self, d_model):\n",
        "        self.output_weights = self.add_weight(\n",
        "            name='output_weights',\n",
        "            shape=(d_model, d_model),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True)\n",
        "        if self.compression_window_size is not None:\n",
        "            self.k_conv_kernel = self.add_weight(\n",
        "                name='k_conv_kernel',\n",
        "                shape=(self.compression_window_size,\n",
        "                       d_model // self.num_heads,\n",
        "                       d_model // self.num_heads),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "            self.k_conv_bias = self.add_weight(\n",
        "                name='k_conv_bias',\n",
        "                shape=(d_model // self.num_heads,),\n",
        "                initializer='zeros',\n",
        "                trainable=True)\n",
        "            self.v_conv_kernel = self.add_weight(\n",
        "                name='v_conv_kernel',\n",
        "                shape=(self.compression_window_size,\n",
        "                       d_model // self.num_heads,\n",
        "                       d_model // self.num_heads),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "            self.v_conv_bias = self.add_weight(\n",
        "                name='v_conv_bias',\n",
        "                shape=(d_model // self.num_heads,),\n",
        "                initializer='zeros',\n",
        "                trainable=True)\n",
        "\n",
        "    def validate_model_dimensionality(self, d_model: int):\n",
        "        if d_model % self.num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f'The size of the last dimension of the input '\n",
        "                f'({d_model}) must be evenly divisible by the number'\n",
        "                f'of the attention heads {self.num_heads}')\n",
        "\n",
        "    def attention(self, pre_q, pre_v, pre_k, out_seq_len: int, d_model: int,\n",
        "                  training=None):\n",
        "  \n",
        "        # shaping Q and V into (batch_size, num_heads, seq_len, d_model//heads)\n",
        "        q = K.permute_dimensions(pre_q, [0, 2, 1, 3])\n",
        "        v = K.permute_dimensions(pre_v, [0, 2, 1, 3])\n",
        "\n",
        "        if self.compression_window_size is None:\n",
        "            k_transposed = K.permute_dimensions(pre_k, [0, 2, 3, 1])\n",
        "        else:\n",
        "            if self.use_masking:\n",
        "                raise NotImplementedError(\n",
        "                    \"Masked memory-compressed attention has not \"\n",
        "                    \"been implemented yet\")\n",
        "            k = K.permute_dimensions(pre_k, [0, 2, 1, 3])\n",
        "            k, v = [\n",
        "                K.reshape(\n",
        "                    # Step 3: Return the result to its original dimensions\n",
        "                    # (batch_size, num_heads, seq_len, d_model//heads)\n",
        "                    K.bias_add(\n",
        "                        # Step 3: ... and add bias\n",
        "                        K.conv1d(\n",
        "                            # Step 2: we \"compress\" K and V using strided conv\n",
        "                            K.reshape(\n",
        "                                # Step 1: we reshape K and V to\n",
        "                                # (batch + num_heads,  seq_len, d_model//heads)\n",
        "                                item,\n",
        "                                (-1,\n",
        "                                 K.int_shape(item)[-2],\n",
        "                                 d_model // self.num_heads)),\n",
        "                            kernel,\n",
        "                            strides=self.compression_window_size,\n",
        "                            padding='valid', data_format='channels_last'),\n",
        "                        bias,\n",
        "                        data_format='channels_last'),\n",
        "                    # new shape\n",
        "                    K.concatenate([\n",
        "                        K.shape(item)[:2],\n",
        "                        [-1, d_model // self.num_heads]]))\n",
        "                for item, kernel, bias in (\n",
        "                    (k, self.k_conv_kernel, self.k_conv_bias),\n",
        "                    (v, self.v_conv_kernel, self.v_conv_bias))]\n",
        "            k_transposed = K.permute_dimensions(k, [0, 1, 3, 2])\n",
        "        # shaping K into (batch_size, num_heads, d_model//heads, seq_len)\n",
        "        # for further matrix multiplication\n",
        "        sqrt_d = K.constant(np.sqrt(d_model // self.num_heads),\n",
        "                            dtype=K.floatx())\n",
        "        q_shape = K.int_shape(q)\n",
        "        k_t_shape = K.int_shape(k_transposed)\n",
        "        v_shape = K.int_shape(v)\n",
        "        # before performing batch_dot all tensors are being converted to 3D\n",
        "        # shape (batch_size * num_heads, rows, cols) to make sure batch_dot\n",
        "        # performs identically on all backends\n",
        "        attention_heads = K.reshape(\n",
        "            K.batch_dot(\n",
        "                self.apply_dropout_if_needed(\n",
        "                    K.softmax(\n",
        "                        self.mask_attention_if_needed(\n",
        "                            K.batch_dot(\n",
        "                                K.reshape(q, (-1,) + q_shape[-2:]),\n",
        "                                K.reshape(k_transposed,\n",
        "                                          (-1,) + k_t_shape[-2:]))\n",
        "                            / sqrt_d)),\n",
        "                    training=training),\n",
        "                K.reshape(v, (-1,) + v_shape[-2:])),\n",
        "            (-1, self.num_heads, q_shape[-2], v_shape[-1]))\n",
        "        attention_heads_merged = K.reshape(\n",
        "            K.permute_dimensions(attention_heads, [0, 2, 1, 3]),\n",
        "            (-1, d_model))\n",
        "        attention_out = K.reshape(\n",
        "            K.dot(attention_heads_merged, self.output_weights),\n",
        "            (-1, out_seq_len, d_model))\n",
        "        return attention_out\n",
        "\n",
        "    def apply_dropout_if_needed(self, attention_softmax, training=None):\n",
        "        if 0.0 < self.dropout < 1.0:\n",
        "            def dropped_softmax():\n",
        "                return K.dropout(attention_softmax, self.dropout)\n",
        "\n",
        "            return K.in_train_phase(dropped_softmax, attention_softmax,\n",
        "                                    training=training)\n",
        "        return attention_softmax\n",
        "\n",
        "    def mask_attention_if_needed(self, dot_product):\n",
        "        if not self.use_masking:\n",
        "            return dot_product\n",
        "        last_dims = K.int_shape(dot_product)[-2:]\n",
        "        low_triangle_ones = (\n",
        "            np.tril(np.ones(last_dims))\n",
        "            # to ensure proper broadcasting\n",
        "            .reshape((1,) + last_dims))\n",
        "        inverse_low_triangle = 1 - low_triangle_ones\n",
        "        close_to_negative_inf = -1e9\n",
        "        result = (\n",
        "            K.constant(low_triangle_ones, dtype=K.floatx()) * dot_product +\n",
        "            K.constant(close_to_negative_inf * inverse_low_triangle))\n",
        "        return result\n",
        "\n",
        "\n",
        "class MultiHeadAttention(_BaseMultiHeadAttention):\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if not (isinstance(input_shape, list) and len(input_shape) == 2):\n",
        "            raise ValueError(\n",
        "                'You must call this layer passing a list of two tensors'\n",
        "                '(for keys/values and queries)')\n",
        "        values_dim, query_dim = input_shape[0][-1], input_shape[1][-1]\n",
        "        if query_dim != values_dim:\n",
        "            raise ValueError(\n",
        "                f'Both keys/value and query inputs must be '\n",
        "                f'of the same dimensionality, instead of '\n",
        "                f'{values_dim} and {query_dim}.')\n",
        "        d_model = query_dim\n",
        "        self.validate_model_dimensionality(d_model)\n",
        "      \n",
        "        self.kv_weights = self.add_weight(\n",
        "            name='kv_weights', shape=(d_model, d_model * 2),\n",
        "            initializer='glorot_uniform', trainable=True)\n",
        "        self.q_weights = self.add_weight(\n",
        "            name='q_weights', shape=(d_model, d_model),\n",
        "            initializer='glorot_uniform', trainable=True)\n",
        "        self.build_output_params(d_model)\n",
        "        return super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if not (isinstance(inputs, list) and len(inputs) == 2):\n",
        "            raise ValueError(\n",
        "                'You can call this layer only with a list of two tensors '\n",
        "                '(for keys/values and queries)')\n",
        "        key_values_input, query_input = inputs\n",
        "        _, value_seq_len, d_model = K.int_shape(key_values_input)\n",
        "        query_seq_len = K.int_shape(inputs[1])[-2]\n",
        "        # The first thing we need to do is to perform affine transformations\n",
        "        # of the inputs to get the Queries, the Keys and the Values.\n",
        "        kv = K.dot(K.reshape(key_values_input, [-1, d_model]), self.kv_weights)\n",
        "        # splitting the keys, the values and the queries before further\n",
        "        # processing\n",
        "        pre_k, pre_v = [\n",
        "            K.reshape(\n",
        "                # K.slice(kv, (0, i * d_model), (-1, d_model)),\n",
        "                kv[:, i * d_model: (i + 1) * d_model],\n",
        "                (-1, value_seq_len,\n",
        "                 self.num_heads, d_model // self.num_heads))\n",
        "            for i in range(2)]\n",
        "        pre_q = K.reshape(\n",
        "            K.dot(K.reshape(query_input, [-1, d_model]), self.q_weights),\n",
        "            (-1, query_seq_len, self.num_heads, d_model // self.num_heads))\n",
        "        return self.attention(pre_q, pre_v, pre_k, query_seq_len, d_model,\n",
        "                              training=kwargs.get('training'))\n",
        "\n",
        "\n",
        "class MultiHeadSelfAttention(_BaseMultiHeadAttention):\n",
        "\n",
        "    # noinspection PyAttributeOutsideInit\n",
        "    def build(self, input_shape):\n",
        "        if not isinstance(input_shape, tuple):\n",
        "            raise ValueError('Invalid input')\n",
        "        d_model = input_shape[-1]\n",
        "        self.validate_model_dimensionality(d_model)\n",
        "\n",
        "        self.qkv_weights = self.add_weight(\n",
        "            name='qkv_weights',\n",
        "            shape=(d_model, d_model * 3),  # * 3 for q, k and v\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True)\n",
        "        self.build_output_params(d_model)\n",
        "        return super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if not K.is_tensor(inputs):\n",
        "            raise ValueError(\n",
        "                'The layer can be called only with one tensor as an argument')\n",
        "        _, seq_len, d_model = K.int_shape(inputs)\n",
        "        # The first thing we need to do is to perform affine transformations\n",
        "        # of the inputs to get the Queries, the Keys and the Values.\n",
        "        qkv = K.dot(K.reshape(inputs, [-1, d_model]), self.qkv_weights)\n",
        "        # splitting the keys, the values and the queries before further\n",
        "        # processing\n",
        "        pre_q, pre_k, pre_v = [\n",
        "            K.reshape(\n",
        "                # K.slice(qkv, (0, i * d_model), (-1, d_model)),\n",
        "                qkv[:, i * d_model:(i + 1) * d_model],\n",
        "                (-1, seq_len, self.num_heads, d_model // self.num_heads))\n",
        "            for i in range(3)]\n",
        "        attention_out = self.attention(pre_q, pre_v, pre_k, seq_len, d_model,\n",
        "                                       training=kwargs.get('training'))\n",
        "        return attention_out\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'MultiHeadSelfAttention': MultiHeadSelfAttention,\n",
        "    'MultiHeadAttention': MultiHeadAttention,\n",
        "})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T1VD-h9sldOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.engine import Layer\n",
        "from keras.utils import get_custom_objects\n",
        "\n",
        "\n",
        "def positional_signal(hidden_size: int, length: int,\n",
        "                      min_timescale: float = 1.0, max_timescale: float = 1e4):\n",
        "    if hidden_size % 2 != 0:\n",
        "        raise ValueError(\n",
        "            f\"The hidden dimension of the model must be divisible by 2.\"\n",
        "            f\"Currently it is {hidden_size}\")\n",
        "    position = K.arange(0, length, dtype=K.floatx())\n",
        "    num_timescales = hidden_size // 2\n",
        "    log_timescale_increment = K.constant(\n",
        "        (np.log(float(max_timescale) / float(min_timescale)) /\n",
        "         (num_timescales - 1)),\n",
        "        dtype=K.floatx())\n",
        "    inv_timescales = (\n",
        "            min_timescale *\n",
        "            K.exp(K.arange(num_timescales, dtype=K.floatx()) *\n",
        "                  -log_timescale_increment))\n",
        "    scaled_time = K.expand_dims(position, 1) * K.expand_dims(inv_timescales, 0)\n",
        "    signal = K.concatenate([K.sin(scaled_time), K.cos(scaled_time)], axis=1)\n",
        "    return K.expand_dims(signal, axis=0)\n",
        "\n",
        "\n",
        "class AddPositionalEncoding(Layer):\n",
        "\n",
        "    def __init__(self, min_timescale: float = 1.0,\n",
        "                 max_timescale: float = 1.0e4, **kwargs):\n",
        "        self.min_timescale = min_timescale\n",
        "        self.max_timescale = max_timescale\n",
        "        self.signal = None\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config['min_timescale'] = self.min_timescale\n",
        "        config['max_timescale'] = self.max_timescale\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, length, hidden_size = input_shape\n",
        "        self.signal = positional_signal(\n",
        "            hidden_size, length, self.min_timescale, self.max_timescale)\n",
        "        return super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return inputs + self.signal\n",
        "\n",
        "\n",
        "class AddCoordinateEncoding(AddPositionalEncoding):\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super().build(input_shape)\n",
        "        _, length, hidden_size = input_shape\n",
        "\n",
        "    def call(self, inputs, step=None, **kwargs):\n",
        "        if step is None:\n",
        "            raise ValueError(\"Please, provide current Transformer's step\"\n",
        "                             \"using 'step' keyword argument.\")\n",
        "        pos_encoded_added = super().call(inputs, **kwargs)\n",
        "        step_signal = K.expand_dims(self.signal[:, step, :], axis=1)\n",
        "        return pos_encoded_added + step_signal\n",
        "\n",
        "\n",
        "class TransformerCoordinateEmbedding(Layer):\n",
        "\n",
        "    def __init__(self, max_transformer_depth: int, **kwargs):\n",
        "        self.max_depth = max_transformer_depth\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config['max_transformer_depth'] = self.max_depth\n",
        "        return config\n",
        "\n",
        "    # noinspection PyAttributeOutsideInit\n",
        "    def build(self, input_shape):\n",
        "        sequence_length, d_model = input_shape[-2:]\n",
        "        self.word_position_embeddings = self.add_weight(\n",
        "            shape=(sequence_length, d_model),\n",
        "            initializer='uniform',\n",
        "            name='word_position_embeddings',\n",
        "            trainable=True)\n",
        "        self.depth_embeddings = self.add_weight(\n",
        "            shape=(self.max_depth, d_model),\n",
        "            initializer='uniform',\n",
        "            name='depth_position_embeddings',\n",
        "            trainable=True)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        depth = kwargs.get('step')\n",
        "        if depth is None:\n",
        "            raise ValueError(\"Please, provide current Transformer's step\"\n",
        "                             \"using 'step' keyword argument.\")\n",
        "        result = inputs + self.word_position_embeddings\n",
        "        if depth is not None:\n",
        "            result = result + self.depth_embeddings[depth]\n",
        "        return result\n",
        "\n",
        "\n",
        "get_custom_objects().update({\n",
        "    'TransformerCoordinateEmbedding': TransformerCoordinateEmbedding,\n",
        "    'AddCoordinateEncoding': AddCoordinateEncoding,\n",
        "    'AddPositionalEncoding': AddCoordinateEncoding,\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-L_25tZ-tPxu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LayerNormalization(Layer):\n",
        "\n",
        "    def __init__(self, axis=-1, **kwargs):\n",
        "        self.axis = axis\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config['axis'] = self.axis\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        dim = input_shape[-1]\n",
        "        self.gain = self.add_weight(\n",
        "            name='gain',\n",
        "            shape=(dim,),\n",
        "            initializer='ones',\n",
        "            trainable=True)\n",
        "        self.bias = self.add_weight(\n",
        "            name='bias',\n",
        "            shape=(dim,),\n",
        "            initializer='zeros',\n",
        "            trainable=True)\n",
        "        return super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        mean = K.mean(inputs, axis=self.axis, keepdims=True)\n",
        "        variance = K.mean(\n",
        "            K.square(inputs - mean), axis=self.axis, keepdims=True)\n",
        "        epsilon = K.constant(1e-5, dtype=K.floatx())\n",
        "        normalized_inputs = (inputs - mean) / K.sqrt(variance + epsilon)\n",
        "        result = self.gain * normalized_inputs + self.bias\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8bv3WiwzljzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2267
        },
        "outputId": "4a91d001-8ab2-43e1-c9aa-15b39f61887a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as Backend\n",
        "from scipy.special import softmax\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from self_attention import MultiHeadSelfAttention\n",
        "from position import AddPositionalEncoding, TransformerCoordinateEmbedding\n",
        "\n",
        "\n",
        "MAX_SENT_LENGTH = 240\n",
        "MAX_SENTS = 40\n",
        "VALIDATION_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.1\n",
        "\n",
        "print('(1) loading ham_docs...')\n",
        "ham_docs = np.load('forbert/ott/train_docs.npy')\n",
        "print(' train_docs finished! shape is:'+str(np.shape(ham_docs)))\n",
        "\n",
        "print('(2) loading spam_docs...')\n",
        "spam_docs = np.load('forbert/ott/val_docs.npy')\n",
        "print(' val_docs finished! shape is:'+str(np.shape(spam_docs)))\n",
        "\n",
        "print('(3) shuffling docs & labels...')\n",
        "ham_labels = open('forbert/ya.txt', encoding='utf-8').read().split('\\n')\n",
        "spam_labels = open('forbert/yb.txt', encoding='utf-8').read().split('\\n')\n",
        "all_labels = ham_labels + spam_labels\n",
        "\n",
        "all_labels = to_categorical(np.asarray(all_labels))\n",
        "all_docs = np.concatenate((ham_docs, spam_docs),axis=0)\n",
        "\n",
        "idx = np.random.permutation(len(all_docs))\n",
        "all_docs = all_docs[idx]\n",
        "all_labels = all_labels[idx]\n",
        "\n",
        "print('(4) splitting data set...')\n",
        "p1 = int(len(all_docs)*(1-VALIDATION_SPLIT-TEST_SPLIT))\n",
        "p2 = int(len(all_docs)*(1-TEST_SPLIT))\n",
        "train_docs = all_docs[:p1]\n",
        "val_docs = all_docs[p1:p2]\n",
        "test_docs = all_docs[p2:]\n",
        "\n",
        "train_labels = all_labels[:p1]\n",
        "val_labels = all_labels[p1:p2]\n",
        "test_labels = all_labels[p2:]\n",
        "\n",
        "tf_train = tf.convert_to_tensor(train_docs, dtype=tf.float32)\n",
        "tf_val = tf.convert_to_tensor(val_docs, dtype=tf.float32)\n",
        "#tf_test = tf.convert_to_tensor(test_docs, dtype=tf.float32)\n",
        "\n",
        "print(len(train_docs))\n",
        "print(len(val_docs))\n",
        "print(len(test_docs))\n",
        "print(len(train_labels))\n",
        "print(len(val_labels))\n",
        "print(len(test_labels))\n",
        "\n",
        "print('(3) building downstream model...')\n",
        "doc_input = Input(shape=(MAX_SENTS, 768), dtype='float32')\n",
        "pos = AddPositionalEncoding()(doc_input)\n",
        "drop1 = Dropout(0.7)(pos)\n",
        "\n",
        "doc_encoder = MultiHeadSelfAttention(num_heads=8, use_masking=False)(drop1)\n",
        "ln1 = LayerNormalization()(doc_encoder)\n",
        "drop2 = Dropout(0.7)(ln1)\n",
        "\n",
        "flat = Flatten()(drop2)\n",
        "dense = Dense(384, activation='relu')(flat)\n",
        "ln2 = LayerNormalization()(dense)\n",
        "drop3 = Dropout(0.7)(ln2)\n",
        "\n",
        "pred = Dense(2, activation='sigmoid')(drop3)\n",
        "\n",
        "model = Model(doc_input, pred)\n",
        "model.summary()\n",
        "#plot_model(model, to_file='D:/TBdata/result/model-so2bert.png',show_shapes=True)\n",
        "#adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.9, epsilon=None, decay=0.0001, amsgrad=False)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "print (model.metrics_names)\n",
        "history = model.fit(tf_train, train_labels, validation_data=(tf_val, val_labels), epochs=30, steps_per_epoch=80, validation_steps=16)\n",
        "\n",
        "print(model.evaluate(val_docs, val_labels))\n",
        "\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve,auc, confusion_matrix, classification_report\n",
        "\n",
        "y_score = model.predict(test_docs)\n",
        "y_pred_labels = np.argmax(y_score, axis=1)\n",
        "y_test_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "\n",
        "print(\"classification_report(left: labels):\")\n",
        "print(classification_report(y_test_labels, y_pred_labels))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1) loading ham_docs...\n",
            " train_docs finished! shape is:(1280, 40, 768)\n",
            "(2) loading spam_docs...\n",
            " val_docs finished! shape is:(320, 40, 768)\n",
            "(3) shuffling docs & labels...\n",
            "(4) splitting data set...\n",
            "1280\n",
            "160\n",
            "160\n",
            "1280\n",
            "160\n",
            "160\n",
            "(3) building downstream model...\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 40, 768)           0         \n",
            "_________________________________________________________________\n",
            "add_positional_encoding_8 (A (None, 40, 768)           0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 40, 768)           0         \n",
            "_________________________________________________________________\n",
            "multi_head_self_attention_8  (None, 40, 768)           2359296   \n",
            "_________________________________________________________________\n",
            "layer_normalization_15 (Laye (None, 40, 768)           1536      \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 40, 768)           0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 30720)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 384)               11796864  \n",
            "_________________________________________________________________\n",
            "layer_normalization_16 (Laye (None, 384)               768       \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 2)                 770       \n",
            "=================================================================\n",
            "Total params: 14,159,234\n",
            "Trainable params: 14,159,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "['loss', 'acc']\n",
            "Train on 1280 samples, validate on 160 samples\n",
            "Epoch 1/30\n",
            "80/80 [==============================] - 24s 302ms/step - loss: 0.8589 - acc: 0.5057 - val_loss: 0.7036 - val_acc: 0.4812\n",
            "Epoch 2/30\n",
            "80/80 [==============================] - 23s 286ms/step - loss: 0.5425 - acc: 0.7248 - val_loss: 0.3559 - val_acc: 0.8562\n",
            "Epoch 3/30\n",
            "80/80 [==============================] - 24s 295ms/step - loss: 0.3996 - acc: 0.8205 - val_loss: 0.3215 - val_acc: 0.8875\n",
            "Epoch 4/30\n",
            "80/80 [==============================] - 23s 288ms/step - loss: 0.3598 - acc: 0.8401 - val_loss: 0.2926 - val_acc: 0.9000\n",
            "Epoch 5/30\n",
            "80/80 [==============================] - 23s 286ms/step - loss: 0.3109 - acc: 0.8660 - val_loss: 0.3018 - val_acc: 0.9062\n",
            "Epoch 6/30\n",
            "80/80 [==============================] - 23s 288ms/step - loss: 0.2841 - acc: 0.8785 - val_loss: 0.3123 - val_acc: 0.8844\n",
            "Epoch 7/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.2594 - acc: 0.8900 - val_loss: 0.3060 - val_acc: 0.8906\n",
            "Epoch 8/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.2427 - acc: 0.8979 - val_loss: 0.3038 - val_acc: 0.8938\n",
            "Epoch 9/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.2152 - acc: 0.9110 - val_loss: 0.3018 - val_acc: 0.9000\n",
            "Epoch 10/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.2007 - acc: 0.9189 - val_loss: 0.3232 - val_acc: 0.8781\n",
            "Epoch 11/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1853 - acc: 0.9247 - val_loss: 0.3103 - val_acc: 0.8938\n",
            "Epoch 12/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1739 - acc: 0.9301 - val_loss: 0.3233 - val_acc: 0.9000\n",
            "Epoch 13/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1628 - acc: 0.9357 - val_loss: 0.3487 - val_acc: 0.8750\n",
            "Epoch 14/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1503 - acc: 0.9414 - val_loss: 0.3368 - val_acc: 0.8656\n",
            "Epoch 15/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1433 - acc: 0.9437 - val_loss: 0.2953 - val_acc: 0.9062\n",
            "Epoch 16/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1372 - acc: 0.9468 - val_loss: 0.3091 - val_acc: 0.8938\n",
            "Epoch 17/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1267 - acc: 0.9508 - val_loss: 0.3883 - val_acc: 0.9000\n",
            "Epoch 18/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1286 - acc: 0.9499 - val_loss: 0.3231 - val_acc: 0.9000\n",
            "Epoch 19/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1176 - acc: 0.9553 - val_loss: 0.3481 - val_acc: 0.9125\n",
            "Epoch 20/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1135 - acc: 0.9567 - val_loss: 0.3331 - val_acc: 0.9094\n",
            "Epoch 21/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1130 - acc: 0.9570 - val_loss: 0.3657 - val_acc: 0.8813\n",
            "Epoch 22/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1093 - acc: 0.9582 - val_loss: 0.3965 - val_acc: 0.8750\n",
            "Epoch 23/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.1043 - acc: 0.9611 - val_loss: 0.3559 - val_acc: 0.8813\n",
            "Epoch 24/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.0995 - acc: 0.9626 - val_loss: 0.3714 - val_acc: 0.8719\n",
            "Epoch 25/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.0925 - acc: 0.9652 - val_loss: 0.3832 - val_acc: 0.8781\n",
            "Epoch 26/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.0921 - acc: 0.9651 - val_loss: 0.3507 - val_acc: 0.9062\n",
            "Epoch 27/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.0926 - acc: 0.9661 - val_loss: 0.3699 - val_acc: 0.8844\n",
            "Epoch 28/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.0908 - acc: 0.9668 - val_loss: 0.3963 - val_acc: 0.8875\n",
            "Epoch 29/30\n",
            "80/80 [==============================] - 23s 290ms/step - loss: 0.0872 - acc: 0.9676 - val_loss: 0.3617 - val_acc: 0.8844\n",
            "Epoch 30/30\n",
            "80/80 [==============================] - 23s 289ms/step - loss: 0.0823 - acc: 0.9693 - val_loss: 0.3491 - val_acc: 0.8938\n",
            "160/160 [==============================] - 0s 2ms/step\n",
            "[0.3491245448589325, 0.89375]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "classification_report(left: labels):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.75      0.81        72\n",
            "           1       0.82      0.92      0.87        88\n",
            "\n",
            "   micro avg       0.84      0.84      0.84       160\n",
            "   macro avg       0.85      0.84      0.84       160\n",
            "weighted avg       0.85      0.84      0.84       160\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M3CzIs4fnK4d",
        "colab_type": "code",
        "outputId": "f4cd5f6f-f257-4e4e-ec96-7103b59bd9e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2625
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as Backend\n",
        "from scipy.special import softmax\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "MAX_SENT_LENGTH = 210\n",
        "MAX_SENTS = 24\n",
        "VALIDATION_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.1\n",
        "\n",
        "print('(1) loading ham_docs...')\n",
        "ham_docs = np.load('forbert/ott/dr_ham.npy')\n",
        "#tf_train=tf.convert_to_tensor(train_docs, dtype=tf.float32)\n",
        "print(' train_docs finished! shape is:'+str(np.shape(ham_docs)))\n",
        "\n",
        "print('(2) loading spam_docs...')\n",
        "spam_docs = np.load('forbert/ott/dr_spam.npy')\n",
        "#tf_val=tf.convert_to_tensor(val_docs, dtype=tf.float32)\n",
        "print(' val_docs finished! shape is:'+str(np.shape(spam_docs)))\n",
        "\n",
        "print('(3) shuffling docs & labels...')\n",
        "ham_labels = open('forbert/ott/dr_ham.txt', encoding='utf-8').read().split('\\n')\n",
        "spam_labels = open('forbert/ott/dr_spam.txt', encoding='utf-8').read().split('\\n')\n",
        "all_labels = ham_labels + spam_labels\n",
        "\n",
        "all_labels = to_categorical(np.asarray(all_labels))\n",
        "all_docs = np.concatenate((ham_docs, spam_docs),axis=0)\n",
        "\n",
        "idx = np.random.permutation(len(all_docs))\n",
        "all_docs = all_docs[idx]\n",
        "all_labels = all_labels[idx]\n",
        "\n",
        "print('(4) splitting data set...')\n",
        "p1 = int(len(all_docs)*(1-VALIDATION_SPLIT-TEST_SPLIT))\n",
        "p2 = int(len(all_docs)*(1-TEST_SPLIT))\n",
        "train_docs = all_docs[:p1]\n",
        "val_docs = all_docs[p1:p2]\n",
        "test_docs = all_docs[p2:]\n",
        "\n",
        "train_labels = all_labels[:p1]\n",
        "val_labels = all_labels[p1:p2]\n",
        "test_labels = all_labels[p2:]\n",
        "\n",
        "tf_train = tf.convert_to_tensor(train_docs, dtype=tf.float32)\n",
        "tf_val = tf.convert_to_tensor(val_docs, dtype=tf.float32)\n",
        "#tf_test = tf.convert_to_tensor(test_docs, dtype=tf.float32)\n",
        "\n",
        "print(len(train_docs))\n",
        "print(len(val_docs))\n",
        "print(len(test_docs))\n",
        "print(len(train_labels))\n",
        "print(len(val_labels))\n",
        "print(len(test_labels))\n",
        "\n",
        "print('(5) building downstream model...')\n",
        "doc_input = Input(shape=(MAX_SENTS, 768), dtype='float32')\n",
        "pos = AddPositionalEncoding()(doc_input)\n",
        "drop1 = Dropout(0.3)(pos)\n",
        "\n",
        "doc_encoder = MultiHeadSelfAttention(num_heads=8, use_masking=False)(drop1)\n",
        "ln1 = LayerNormalization()(doc_encoder)\n",
        "drop2 = Dropout(0.3)(ln1)\n",
        "\n",
        "flat = Flatten()(drop2)\n",
        "dense = Dense(384, activation='relu')(flat)\n",
        "ln2 = LayerNormalization()(dense)\n",
        "drop3 = Dropout(0.3)(ln2)\n",
        "\n",
        "pred = Dense(2, activation='sigmoid')(drop3)\n",
        "\n",
        "model = Model(doc_input, pred)\n",
        "model.summary()\n",
        "#plot_model(model, to_file='D:/TBdata/result/model-so2bert.png',show_shapes=True)\n",
        "#adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.9, epsilon=None, decay=0.0001, amsgrad=False)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "print (model.metrics_names)\n",
        "history = model.fit(tf_train, train_labels, validation_data=(tf_val, val_labels), epochs=20, steps_per_epoch=28, validation_steps=4)\n",
        "\n",
        "print(model.evaluate(val_docs, val_labels))\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve,auc, confusion_matrix, classification_report\n",
        "\n",
        "y_score = model.predict(test_docs)\n",
        "y_pred_labels = np.argmax(y_score, axis=1)\n",
        "y_test_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "\n",
        "print(\"classification_report(left: labels):\")\n",
        "print(classification_report(y_test_labels, y_pred_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1) loading ham_docs...\n",
            " train_docs finished! shape is:(200, 24, 768)\n",
            "(2) loading spam_docs...\n",
            " val_docs finished! shape is:(356, 24, 768)\n",
            "(3) shuffling docs & labels...\n",
            "(4) splitting data set...\n",
            "444\n",
            "56\n",
            "56\n",
            "444\n",
            "56\n",
            "56\n",
            "(5) building downstream model...\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 24, 768)           0         \n",
            "_________________________________________________________________\n",
            "add_positional_encoding_5 (A (None, 24, 768)           0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 24, 768)           0         \n",
            "_________________________________________________________________\n",
            "multi_head_self_attention_5  (None, 24, 768)           2359296   \n",
            "_________________________________________________________________\n",
            "layer_normalization_9 (Layer (None, 24, 768)           1536      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 24, 768)           0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 384)               7078272   \n",
            "_________________________________________________________________\n",
            "layer_normalization_10 (Laye (None, 384)               768       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 2)                 770       \n",
            "=================================================================\n",
            "Total params: 9,440,642\n",
            "Trainable params: 9,440,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "['loss', 'acc']\n",
            "Train on 444 samples, validate on 56 samples\n",
            "Epoch 1/20\n",
            "28/28 [==============================] - 3s 119ms/step - loss: 1.6219 - acc: 0.5553 - val_loss: 0.6322 - val_acc: 0.7321\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 2s 66ms/step - loss: 0.6938 - acc: 0.5878 - val_loss: 0.6003 - val_acc: 0.7321\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 2s 66ms/step - loss: 0.6865 - acc: 0.5928 - val_loss: 0.6016 - val_acc: 0.7321\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 2s 66ms/step - loss: 0.6825 - acc: 0.6008 - val_loss: 0.6033 - val_acc: 0.7321\n",
            "Epoch 5/20\n",
            "28/28 [==============================] - 2s 67ms/step - loss: 0.6788 - acc: 0.6059 - val_loss: 0.5996 - val_acc: 0.7321\n",
            "Epoch 6/20\n",
            "28/28 [==============================] - 2s 67ms/step - loss: 0.6672 - acc: 0.6163 - val_loss: 0.5928 - val_acc: 0.7321\n",
            "Epoch 7/20\n",
            "28/28 [==============================] - 2s 67ms/step - loss: 0.5612 - acc: 0.7146 - val_loss: 0.4808 - val_acc: 0.7589\n",
            "Epoch 8/20\n",
            "28/28 [==============================] - 2s 68ms/step - loss: 0.3158 - acc: 0.8689 - val_loss: 0.5038 - val_acc: 0.7857\n",
            "Epoch 9/20\n",
            "28/28 [==============================] - 2s 68ms/step - loss: 0.1919 - acc: 0.9298 - val_loss: 0.2605 - val_acc: 0.8750\n",
            "Epoch 10/20\n",
            "28/28 [==============================] - 2s 68ms/step - loss: 0.1473 - acc: 0.9460 - val_loss: 0.2985 - val_acc: 0.8929\n",
            "Epoch 11/20\n",
            "28/28 [==============================] - 2s 69ms/step - loss: 0.0906 - acc: 0.9677 - val_loss: 0.3438 - val_acc: 0.8929\n",
            "Epoch 12/20\n",
            "28/28 [==============================] - 2s 70ms/step - loss: 0.0669 - acc: 0.9764 - val_loss: 0.3839 - val_acc: 0.8571\n",
            "Epoch 13/20\n",
            "28/28 [==============================] - 2s 70ms/step - loss: 0.0504 - acc: 0.9819 - val_loss: 0.3072 - val_acc: 0.8839\n",
            "Epoch 14/20\n",
            "28/28 [==============================] - 2s 70ms/step - loss: 0.0391 - acc: 0.9868 - val_loss: 0.3354 - val_acc: 0.8929\n",
            "Epoch 15/20\n",
            "28/28 [==============================] - 2s 71ms/step - loss: 0.0366 - acc: 0.9876 - val_loss: 0.2011 - val_acc: 0.9286\n",
            "Epoch 16/20\n",
            "28/28 [==============================] - 2s 71ms/step - loss: 0.0297 - acc: 0.9897 - val_loss: 0.2663 - val_acc: 0.9018\n",
            "Epoch 17/20\n",
            "28/28 [==============================] - 2s 71ms/step - loss: 0.0265 - acc: 0.9915 - val_loss: 0.3140 - val_acc: 0.9286\n",
            "Epoch 18/20\n",
            "28/28 [==============================] - 2s 71ms/step - loss: 0.0255 - acc: 0.9917 - val_loss: 0.3033 - val_acc: 0.9286\n",
            "Epoch 19/20\n",
            "28/28 [==============================] - 2s 70ms/step - loss: 0.0241 - acc: 0.9920 - val_loss: 0.2035 - val_acc: 0.9464\n",
            "Epoch 20/20\n",
            "28/28 [==============================] - 2s 70ms/step - loss: 0.0176 - acc: 0.9949 - val_loss: 0.2651 - val_acc: 0.9464\n",
            "56/56 [==============================] - 0s 3ms/step\n",
            "[0.2650511222226279, 0.9464285799435207]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npZTqoKGglFKqg4aCUkqpDv8feYOHgeQ8MooAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "computing f1 score...\n",
            "[[32  4]\n",
            " [ 3 17]]\n",
            "False\n",
            "False\n",
            "[0.88888889 0.85      ]\n",
            "[0.88888889 0.85      ]\n",
            "[0.88888889 0.85      ]\n",
            "classification_report(left: labels):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90        36\n",
            "           1       0.81      0.85      0.83        20\n",
            "\n",
            "   micro avg       0.88      0.88      0.88        56\n",
            "   macro avg       0.86      0.87      0.87        56\n",
            "weighted avg       0.88      0.88      0.88        56\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PZrpR7uFEojH",
        "colab_type": "code",
        "outputId": "6fc56709-9b32-4eac-dce0-cf38280bf436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2677
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_SENT_LENGTH = 210\n",
        "MAX_SENTS = 24\n",
        "VALIDATION_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.1\n",
        "\n",
        "print('(1) loading ham_docs...')\n",
        "ham_docs = np.load('forbert/ott/res_ham.npy')\n",
        "#tf_train=tf.convert_to_tensor(train_docs, dtype=tf.float32)\n",
        "print(' train_docs finished! shape is:'+str(np.shape(ham_docs)))\n",
        "\n",
        "print('(2) loading spam_docs...')\n",
        "spam_docs = np.load('forbert/ott/res_spam.npy')\n",
        "#tf_val=tf.convert_to_tensor(val_docs, dtype=tf.float32)\n",
        "print(' val_docs finished! shape is:'+str(np.shape(spam_docs)))\n",
        "\n",
        "print('(3) shuffling docs & labels...')\n",
        "ham_labels = open('forbert/ott/res_ham.txt', encoding='utf-8').read().split('\\n')\n",
        "spam_labels = open('forbert/ott/res_spam.txt', encoding='utf-8').read().split('\\n')\n",
        "all_labels = ham_labels + spam_labels\n",
        "\n",
        "all_labels = to_categorical(np.asarray(all_labels))\n",
        "all_docs = np.concatenate((ham_docs, spam_docs),axis=0)\n",
        "\n",
        "idx = np.random.permutation(len(all_docs))\n",
        "all_docs = all_docs[idx]\n",
        "all_labels = all_labels[idx]\n",
        "\n",
        "print('(4) splitting data set...')\n",
        "p1 = int(len(all_docs)*(1-VALIDATION_SPLIT-TEST_SPLIT))\n",
        "p2 = int(len(all_docs)*(1-TEST_SPLIT))\n",
        "train_docs = all_docs[:p1]\n",
        "val_docs = all_docs[p1:p2]\n",
        "test_docs = all_docs[p2:]\n",
        "\n",
        "train_labels = all_labels[:p1]\n",
        "val_labels = all_labels[p1:p2]\n",
        "test_labels = all_labels[p2:]\n",
        "\n",
        "tf_train = tf.convert_to_tensor(train_docs, dtype=tf.float32)\n",
        "tf_val = tf.convert_to_tensor(val_docs, dtype=tf.float32)\n",
        "#tf_test = tf.convert_to_tensor(test_docs, dtype=tf.float32)\n",
        "\n",
        "print(len(train_docs))\n",
        "print(len(val_docs))\n",
        "#print(len(test_docs))\n",
        "print(len(train_labels))\n",
        "print(len(val_labels))\n",
        "#print(len(test_labels))\n",
        "\n",
        "print('(5) building downstream model...')\n",
        "doc_input = Input(shape=(MAX_SENTS, 768), dtype='float32')\n",
        "pos = AddPositionalEncoding()(doc_input)\n",
        "drop1 = Dropout(0.7)(pos)\n",
        "\n",
        "doc_encoder = MultiHeadSelfAttention(num_heads=8, use_masking=False)(drop1)\n",
        "ln1 = LayerNormalization()(doc_encoder)\n",
        "drop2 = Dropout(0.7)(ln1)\n",
        "\n",
        "flat = Flatten()(drop2)\n",
        "dense = Dense(384, activation='relu')(flat)\n",
        "ln2 = LayerNormalization()(dense)\n",
        "drop3 = Dropout(0.7)(ln2)\n",
        "\n",
        "pred = Dense(2, activation='sigmoid')(drop3)\n",
        "\n",
        "model = Model(doc_input, pred)\n",
        "model.summary()\n",
        "#plot_model(model, to_file='D:/TBdata/result/model-so2bert.png',show_shapes=True)\n",
        "#adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.9, epsilon=None, decay=0.0001, amsgrad=False)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "print (model.metrics_names)\n",
        "history = model.fit(tf_train, train_labels, validation_data=(tf_val, val_labels), epochs=40, steps_per_epoch=40, validation_steps=8)\n",
        "\n",
        "print(model.evaluate(val_docs, val_labels))\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import roc_curve,auc, confusion_matrix, classification_report\n",
        "\n",
        "y_score = model.predict(test_docs)\n",
        "y_pred_labels = np.argmax(y_score, axis=1)\n",
        "y_test_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "print(\"classification_report(left: labels):\")\n",
        "print(classification_report(y_test_labels, y_pred_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1) loading ham_docs...\n",
            " train_docs finished! shape is:(200, 24, 768)\n",
            "(2) loading spam_docs...\n",
            " val_docs finished! shape is:(200, 24, 768)\n",
            "(3) shuffling docs & labels...\n",
            "(4) splitting data set...\n",
            "320\n",
            "40\n",
            "320\n",
            "40\n",
            "(5) building downstream model...\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_50 (InputLayer)        (None, 24, 768)           0         \n",
            "_________________________________________________________________\n",
            "add_positional_encoding_50 ( (None, 24, 768)           0         \n",
            "_________________________________________________________________\n",
            "dropout_148 (Dropout)        (None, 24, 768)           0         \n",
            "_________________________________________________________________\n",
            "multi_head_self_attention_50 (None, 24, 768)           2359296   \n",
            "_________________________________________________________________\n",
            "layer_normalization_99 (Laye (None, 24, 768)           1536      \n",
            "_________________________________________________________________\n",
            "dropout_149 (Dropout)        (None, 24, 768)           0         \n",
            "_________________________________________________________________\n",
            "flatten_50 (Flatten)         (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 384)               7078272   \n",
            "_________________________________________________________________\n",
            "layer_normalization_100 (Lay (None, 384)               768       \n",
            "_________________________________________________________________\n",
            "dropout_150 (Dropout)        (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 2)                 770       \n",
            "=================================================================\n",
            "Total params: 9,440,642\n",
            "Trainable params: 9,440,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "['loss', 'acc']\n",
            "Train on 320 samples, validate on 40 samples\n",
            "Epoch 1/40\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.9783 - acc: 0.4980 - val_loss: 0.7021 - val_acc: 0.4000\n",
            "Epoch 2/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.7278 - acc: 0.5106 - val_loss: 0.6987 - val_acc: 0.4000\n",
            "Epoch 3/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.6262 - acc: 0.6319 - val_loss: 0.3998 - val_acc: 0.8250\n",
            "Epoch 4/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.4076 - acc: 0.8197 - val_loss: 0.3010 - val_acc: 0.8250\n",
            "Epoch 5/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.3327 - acc: 0.8574 - val_loss: 0.3273 - val_acc: 0.8250\n",
            "Epoch 6/40\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.2834 - acc: 0.8829 - val_loss: 0.2777 - val_acc: 0.9000\n",
            "Epoch 7/40\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.2494 - acc: 0.8929 - val_loss: 0.2951 - val_acc: 0.8500\n",
            "Epoch 8/40\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 0.2266 - acc: 0.9084 - val_loss: 0.2801 - val_acc: 0.8750\n",
            "Epoch 9/40\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.1932 - acc: 0.9218 - val_loss: 0.2368 - val_acc: 0.8750\n",
            "Epoch 10/40\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.1899 - acc: 0.9204 - val_loss: 0.2424 - val_acc: 0.8500\n",
            "Epoch 11/40\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.1762 - acc: 0.9288 - val_loss: 0.1739 - val_acc: 0.9000\n",
            "Epoch 12/40\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.1828 - acc: 0.9263 - val_loss: 0.2409 - val_acc: 0.8250\n",
            "Epoch 13/40\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.1526 - acc: 0.9380 - val_loss: 0.2521 - val_acc: 0.8250\n",
            "Epoch 14/40\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.1461 - acc: 0.9428 - val_loss: 0.2481 - val_acc: 0.8500\n",
            "Epoch 15/40\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.1437 - acc: 0.9432 - val_loss: 0.2069 - val_acc: 0.8625\n",
            "Epoch 16/40\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.1372 - acc: 0.9476 - val_loss: 0.2512 - val_acc: 0.8750\n",
            "Epoch 17/40\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.1276 - acc: 0.9520 - val_loss: 0.2400 - val_acc: 0.8750\n",
            "Epoch 18/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.1214 - acc: 0.9526 - val_loss: 0.2248 - val_acc: 0.9125\n",
            "Epoch 19/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.1251 - acc: 0.9518 - val_loss: 0.2090 - val_acc: 0.8750\n",
            "Epoch 20/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.1255 - acc: 0.9513 - val_loss: 0.2732 - val_acc: 0.8250\n",
            "Epoch 21/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.1248 - acc: 0.9504 - val_loss: 0.1857 - val_acc: 0.9000\n",
            "Epoch 22/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.1096 - acc: 0.9596 - val_loss: 0.2236 - val_acc: 0.9250\n",
            "Epoch 23/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.1003 - acc: 0.9607 - val_loss: 0.2344 - val_acc: 0.8500\n",
            "Epoch 24/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.1112 - acc: 0.9575 - val_loss: 0.2303 - val_acc: 0.8000\n",
            "Epoch 25/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.1011 - acc: 0.9609 - val_loss: 0.1748 - val_acc: 0.9000\n",
            "Epoch 26/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.0958 - acc: 0.9624 - val_loss: 0.1906 - val_acc: 0.8750\n",
            "Epoch 27/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0964 - acc: 0.9625 - val_loss: 0.2493 - val_acc: 0.8375\n",
            "Epoch 28/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0959 - acc: 0.9626 - val_loss: 0.2220 - val_acc: 0.9375\n",
            "Epoch 29/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0930 - acc: 0.9647 - val_loss: 0.2396 - val_acc: 0.9125\n",
            "Epoch 30/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0889 - acc: 0.9648 - val_loss: 0.2041 - val_acc: 0.9500\n",
            "Epoch 31/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0887 - acc: 0.9683 - val_loss: 0.2631 - val_acc: 0.8750\n",
            "Epoch 32/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0926 - acc: 0.9656 - val_loss: 0.2203 - val_acc: 0.8500\n",
            "Epoch 33/40\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 0.0933 - acc: 0.9652 - val_loss: 0.2173 - val_acc: 0.9500\n",
            "Epoch 34/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0886 - acc: 0.9667 - val_loss: 0.2256 - val_acc: 0.9000\n",
            "Epoch 35/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0848 - acc: 0.9676 - val_loss: 0.1929 - val_acc: 0.9250\n",
            "Epoch 36/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0867 - acc: 0.9671 - val_loss: 0.2847 - val_acc: 0.8750\n",
            "Epoch 37/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0838 - acc: 0.9689 - val_loss: 0.3073 - val_acc: 0.9000\n",
            "Epoch 38/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0832 - acc: 0.9699 - val_loss: 0.1973 - val_acc: 0.9250\n",
            "Epoch 39/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0791 - acc: 0.9702 - val_loss: 0.2198 - val_acc: 0.9000\n",
            "Epoch 40/40\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 0.0727 - acc: 0.9726 - val_loss: 0.2919 - val_acc: 0.9500\n",
            "40/40 [==============================] - 1s 27ms/step\n",
            "[0.2918958306312561, 0.95]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "classification_report(left: labels):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92        17\n",
            "           1       1.00      0.87      0.93        23\n",
            "\n",
            "   micro avg       0.93      0.93      0.93        40\n",
            "   macro avg       0.93      0.93      0.92        40\n",
            "weighted avg       0.94      0.93      0.93        40\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kl3k-35LoB3m",
        "colab_type": "code",
        "outputId": "a916fb65-72ca-4c07-c856-3f5c1e0929f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2369
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as Backend\n",
        "from scipy.special import softmax\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "MAX_SENT_LENGTH = 210\n",
        "MAX_SENTS = 40\n",
        "VALIDATION_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.1\n",
        "\n",
        "print('(1) loading all docs...')\n",
        "res_ham = np.load('forbert/ott/res_ham.npy')\n",
        "print(' res_ham finished! shape is:'+str(np.shape(res_ham)))\n",
        "res_spam = np.load('forbert/ott/res_spam.npy')\n",
        "print(' res_spam finished! shape is:'+str(np.shape(res_spam)))\n",
        "dr_ham = np.load('forbert/ott/dr_ham.npy')\n",
        "print(' dr_ham finished! shape is:'+str(np.shape(dr_ham)))\n",
        "dr_spam = np.load('forbert/ott/dr_spam.npy')\n",
        "print(' dr_spam finished! shape is:'+str(np.shape(dr_spam)))\n",
        "hot_ham = np.load('forbert/ott/train_docs.npy')\n",
        "print(' hot_ham finished! shape is:'+str(np.shape(hot_ham)))\n",
        "hot_spam = np.load('forbert/ott/val_docs.npy')\n",
        "print(' hot_spam finished! shape is:'+str(np.shape(hot_spam)))\n",
        "\n",
        "all_docs = np.concatenate((res_ham, res_spam, dr_ham, dr_spam),axis=0)\n",
        "print(' all_docs shape is:'+str(np.shape(all_docs)))\n",
        "\n",
        "pad = np.zeros((956, MAX_SENTS, 768))\n",
        "pad[:all_docs.shape[0], :all_docs.shape[1], :all_docs.shape[2]] = all_docs\n",
        "print(' pad shape is:'+str(np.shape(pad)))\n",
        "all_docs = np.concatenate((pad, hot_ham, hot_spam),axis=0)\n",
        "\n",
        "\n",
        "print('(2) shuffling docs & labels...')\n",
        "res_ham_labels = open('forbert/ott/res_ham.txt', encoding='utf-8').read().split('\\n')\n",
        "res_spam_labels = open('forbert/ott/res_spam.txt', encoding='utf-8').read().split('\\n')\n",
        "dr_ham_labels = open('forbert/ott/dr_ham.txt', encoding='utf-8').read().split('\\n')\n",
        "dr_spam_labels = open('forbert/ott/dr_spam.txt', encoding='utf-8').read().split('\\n')\n",
        "hot_ham_labels = open('forbert/ya.txt', encoding='utf-8').read().split('\\n')\n",
        "hot_spam_labels = open('forbert/yb.txt', encoding='utf-8').read().split('\\n')\n",
        "\n",
        "all_labels = res_ham_labels+res_spam_labels+dr_ham_labels+dr_spam_labels+hot_ham_labels+hot_spam_labels\n",
        "all_labels = to_categorical(np.asarray(all_labels))\n",
        "print(' all_labels shape is:'+str(np.shape(all_labels)))\n",
        "\n",
        "idx = np.random.permutation(len(all_docs))\n",
        "all_docs = all_docs[idx]\n",
        "all_labels = all_labels[idx]\n",
        "\n",
        "print('(4) splitting data set...')\n",
        "p1 = int(len(all_docs)*(1-VALIDATION_SPLIT-TEST_SPLIT))\n",
        "p2 = int(len(all_docs)*(1-TEST_SPLIT))\n",
        "train_docs = all_docs[:p1]\n",
        "val_docs = all_docs[p1:p2]\n",
        "test_docs = all_docs[p2:]\n",
        "\n",
        "train_labels = all_labels[:p1]\n",
        "val_labels = all_labels[p1:p2]\n",
        "test_labels = all_labels[p2:]\n",
        "\n",
        "tf_train = tf.convert_to_tensor(train_docs, dtype=tf.float32)\n",
        "tf_val = tf.convert_to_tensor(val_docs, dtype=tf.float32)\n",
        "#tf_test = tf.convert_to_tensor(test_docs, dtype=tf.float32)\n",
        "\n",
        "print(len(train_docs))\n",
        "print(len(val_docs))\n",
        "print(len(test_docs))\n",
        "print(len(train_labels))\n",
        "print(len(val_labels))\n",
        "print(len(test_labels))\n",
        "\n",
        "print('(5) building downstream model...')\n",
        "doc_input = Input(shape=(MAX_SENTS, 768), dtype='float32')\n",
        "pos = AddPositionalEncoding()(doc_input)\n",
        "drop1 = Dropout(0.6)(pos)\n",
        "\n",
        "doc_encoder = MultiHeadSelfAttention(num_heads=8, use_masking=False)(drop1)\n",
        "ln1 = LayerNormalization()(doc_encoder)\n",
        "drop2 = Dropout(0.6)(ln1)\n",
        "\n",
        "flat = Flatten()(drop2)\n",
        "dense = Dense(384, activation='relu')(flat)\n",
        "ln2 = LayerNormalization()(dense)\n",
        "drop3 = Dropout(0.6)(ln2)\n",
        "\n",
        "pred = Dense(2, activation='sigmoid')(drop3)\n",
        "\n",
        "model = Model(doc_input, pred)\n",
        "model.summary()\n",
        "#plot_model(model, to_file='D:/TBdata/result/model-so2bert.png',show_shapes=True)\n",
        "#adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.9, epsilon=None, decay=0.0001, amsgrad=False)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "print (model.metrics_names)\n",
        "history = model.fit(tf_train, train_labels, validation_data=(tf_val, val_labels), epochs=30, steps_per_epoch=128, validation_steps=16)\n",
        "\n",
        "print(model.evaluate(val_docs, val_labels))\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import roc_curve,auc, confusion_matrix, classification_report\n",
        "\n",
        "y_score = model.predict(test_docs)\n",
        "y_pred_labels = np.argmax(y_score, axis=1)\n",
        "y_test_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "print(\"classification_report(left: labels):\")\n",
        "print(classification_report(y_test_labels, y_pred_labels))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1) loading all docs...\n",
            " res_ham finished! shape is:(200, 24, 768)\n",
            " res_spam finished! shape is:(200, 24, 768)\n",
            " dr_ham finished! shape is:(200, 24, 768)\n",
            " dr_spam finished! shape is:(356, 24, 768)\n",
            " hot_ham finished! shape is:(1280, 40, 768)\n",
            " hot_spam finished! shape is:(320, 40, 768)\n",
            " all_docs shape is:(956, 24, 768)\n",
            " pad shape is:(956, 40, 768)\n",
            "(2) shuffling docs & labels...\n",
            " all_labels shape is:(2556, 2)\n",
            "(4) splitting data set...\n",
            "2044\n",
            "256\n",
            "256\n",
            "2044\n",
            "256\n",
            "256\n",
            "(5) building downstream model...\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 40, 768)           0         \n",
            "_________________________________________________________________\n",
            "add_positional_encoding_7 (A (None, 40, 768)           0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 40, 768)           0         \n",
            "_________________________________________________________________\n",
            "multi_head_self_attention_7  (None, 40, 768)           2359296   \n",
            "_________________________________________________________________\n",
            "layer_normalization_13 (Laye (None, 40, 768)           1536      \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 40, 768)           0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 30720)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 384)               11796864  \n",
            "_________________________________________________________________\n",
            "layer_normalization_14 (Laye (None, 384)               768       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 2)                 770       \n",
            "=================================================================\n",
            "Total params: 14,159,234\n",
            "Trainable params: 14,159,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "['loss', 'acc']\n",
            "Train on 2044 samples, validate on 256 samples\n",
            "Epoch 1/30\n",
            "128/128 [==============================] - 61s 478ms/step - loss: 0.8408 - acc: 0.5119 - val_loss: 0.7022 - val_acc: 0.4727\n",
            "Epoch 2/30\n",
            "128/128 [==============================] - 58s 454ms/step - loss: 0.6475 - acc: 0.6094 - val_loss: 0.4882 - val_acc: 0.7656\n",
            "Epoch 3/30\n",
            "128/128 [==============================] - 58s 456ms/step - loss: 0.4282 - acc: 0.8053 - val_loss: 0.3208 - val_acc: 0.8516\n",
            "Epoch 4/30\n",
            "128/128 [==============================] - 59s 458ms/step - loss: 0.3599 - acc: 0.8417 - val_loss: 0.3439 - val_acc: 0.8516\n",
            "Epoch 5/30\n",
            "128/128 [==============================] - 58s 457ms/step - loss: 0.2676 - acc: 0.8890 - val_loss: 0.3703 - val_acc: 0.8516\n",
            "Epoch 6/30\n",
            "128/128 [==============================] - 58s 457ms/step - loss: 0.2152 - acc: 0.9124 - val_loss: 0.3151 - val_acc: 0.8711\n",
            "Epoch 7/30\n",
            "128/128 [==============================] - 59s 459ms/step - loss: 0.1762 - acc: 0.9296 - val_loss: 0.3809 - val_acc: 0.8633\n",
            "Epoch 8/30\n",
            "128/128 [==============================] - 59s 457ms/step - loss: 0.1453 - acc: 0.9428 - val_loss: 0.3301 - val_acc: 0.8867\n",
            "Epoch 9/30\n",
            "128/128 [==============================] - 58s 456ms/step - loss: 0.1217 - acc: 0.9528 - val_loss: 0.3483 - val_acc: 0.8730\n",
            "Epoch 10/30\n",
            "128/128 [==============================] - 58s 456ms/step - loss: 0.1067 - acc: 0.9597 - val_loss: 0.3728 - val_acc: 0.8730\n",
            "Epoch 11/30\n",
            "128/128 [==============================] - 59s 459ms/step - loss: 0.0986 - acc: 0.9623 - val_loss: 0.4133 - val_acc: 0.8633\n",
            "Epoch 12/30\n",
            "128/128 [==============================] - 59s 459ms/step - loss: 0.0879 - acc: 0.9670 - val_loss: 0.3877 - val_acc: 0.8730\n",
            "Epoch 13/30\n",
            "128/128 [==============================] - 59s 457ms/step - loss: 0.0775 - acc: 0.9713 - val_loss: 0.3979 - val_acc: 0.8789\n",
            "Epoch 14/30\n",
            "128/128 [==============================] - 58s 457ms/step - loss: 0.0715 - acc: 0.9735 - val_loss: 0.4418 - val_acc: 0.8574\n",
            "Epoch 15/30\n",
            "128/128 [==============================] - 58s 457ms/step - loss: 0.0686 - acc: 0.9744 - val_loss: 0.4302 - val_acc: 0.8789\n",
            "Epoch 16/30\n",
            "128/128 [==============================] - 59s 459ms/step - loss: 0.0630 - acc: 0.9767 - val_loss: 0.4475 - val_acc: 0.8574\n",
            "Epoch 17/30\n",
            "128/128 [==============================] - 59s 457ms/step - loss: 0.0590 - acc: 0.9783 - val_loss: 0.4328 - val_acc: 0.8555\n",
            "Epoch 18/30\n",
            "128/128 [==============================] - 58s 456ms/step - loss: 0.0569 - acc: 0.9792 - val_loss: 0.5261 - val_acc: 0.8516\n",
            "Epoch 19/30\n",
            "128/128 [==============================] - 59s 459ms/step - loss: 0.0530 - acc: 0.9808 - val_loss: 0.5147 - val_acc: 0.8691\n",
            "Epoch 20/30\n",
            "128/128 [==============================] - 59s 460ms/step - loss: 0.0510 - acc: 0.9817 - val_loss: 0.5152 - val_acc: 0.8477\n",
            "Epoch 21/30\n",
            "128/128 [==============================] - 58s 457ms/step - loss: 0.0485 - acc: 0.9826 - val_loss: 0.5243 - val_acc: 0.8672\n",
            "Epoch 22/30\n",
            "128/128 [==============================] - 58s 457ms/step - loss: 0.0489 - acc: 0.9825 - val_loss: 0.5314 - val_acc: 0.8652\n",
            "Epoch 23/30\n",
            "128/128 [==============================] - 59s 458ms/step - loss: 0.0462 - acc: 0.9832 - val_loss: 0.5373 - val_acc: 0.8594\n",
            "Epoch 24/30\n",
            "128/128 [==============================] - 59s 458ms/step - loss: 0.0447 - acc: 0.9839 - val_loss: 0.5556 - val_acc: 0.8672\n",
            "Epoch 25/30\n",
            "128/128 [==============================] - 58s 457ms/step - loss: 0.0430 - acc: 0.9847 - val_loss: 0.6356 - val_acc: 0.8477\n",
            "Epoch 26/30\n",
            "128/128 [==============================] - 58s 456ms/step - loss: 0.0412 - acc: 0.9854 - val_loss: 0.5330 - val_acc: 0.8477\n",
            "Epoch 27/30\n",
            "128/128 [==============================] - 58s 456ms/step - loss: 0.0422 - acc: 0.9850 - val_loss: 0.5492 - val_acc: 0.8594\n",
            "Epoch 28/30\n",
            "128/128 [==============================] - 59s 458ms/step - loss: 0.0413 - acc: 0.9853 - val_loss: 0.5449 - val_acc: 0.8633\n",
            "Epoch 29/30\n",
            "128/128 [==============================] - 59s 457ms/step - loss: 0.0391 - acc: 0.9857 - val_loss: 0.5440 - val_acc: 0.8633\n",
            "Epoch 30/30\n",
            "128/128 [==============================] - 58s 456ms/step - loss: 0.0384 - acc: 0.9865 - val_loss: 0.5130 - val_acc: 0.8828\n",
            "256/256 [==============================] - 0s 931us/step\n",
            "[0.5129575282335281, 0.8828125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxhjTwpKCMcaYFv8fLM+p41UUP4YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "classification_report(left: labels):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85       119\n",
            "           1       0.89      0.84      0.86       137\n",
            "\n",
            "   micro avg       0.86      0.86      0.86       256\n",
            "   macro avg       0.86      0.86      0.86       256\n",
            "weighted avg       0.86      0.86      0.86       256\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}